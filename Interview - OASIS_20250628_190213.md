# Interview - OASIS

原文链接: https://docs.oasis.camel-ai.org/cookbooks/twitter_interview

[OASIS home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/camel-6d2d1ad0/logo/normal_logo.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/camel-6d2d1ad0/logo/white_logo.svg)](https://www.camel-ai.org/)Search...⌘KSearch...NavigationCookbooksInterview[Guides](/introduction)- [Documentation](https://docs.oasis.camel-ai.org/)
- [Community](https://discord.com/invite/CNcNpquyDc)
- [Blog](https://www.camel-ai.org/blogs/oasis)
##### Get Started

* [Introduction](/introduction)
* [Quickstart](/quickstart)
##### Overview

* [Overview](/overview)
##### Key Modules

* [Environment](/key_modules/environments)
* [Agent Graph](/key_modules/agent_graph)
* [Agent Profile](/user_generation/generation)
* [Social Agent](/key_modules/social_agent)
* [Models](/key_modules/models)
* [Toolkits](/key_modules/toolkits)
* [Platform](/key_modules/platform)
* [Actions](/key_modules/actions)
##### Cookbooks

* [Twitter Simulation](/cookbooks/twitter_simulation)
* [Reddit Simulation](/cookbooks/reddit_simulation)
* [Sympy Tools Simulation](/cookbooks/sympy_tools_simulation)
* [Search Tools Simulation](/cookbooks/search_tools_simulation)
* [Custom Prompt Simulation](/cookbooks/custom_prompt_simulation)
* [Interview](/cookbooks/twitter_interview)
##### Visualization

* [Visualization](/visualization/visualization)
Cookbooks
# Interview

Learn how to conduct interviews with AI agents in Twitter simulations using the INTERVIEW action type

# [​](#interview)Interview

This cookbook demonstrates how to use the INTERVIEW action type to conduct interviews with AI agents in a Twitter simulation. The interview functionality allows you to ask specific questions to agents and collect their responses, which is useful for research, opinion polling, and understanding agent behaviors.

## [​](#overview)Overview

The INTERVIEW action type enables you to:

* Ask specific questions to individual agents
* Collect structured responses from agents
* Store interview data in the database for analysis
* Conduct interviews alongside regular social media interactions

## [​](#key-features)Key Features

* **Manual Interview Actions**: Use `ManualAction` with `ActionType.INTERVIEW` to conduct interviews
* **Automatic Response Collection**: The system automatically collects and stores agent responses
* **Database Storage**: All interview data is stored in the trace table for later analysis
* **Concurrent Execution**: Interviews can be conducted alongside other social media actions

## [​](#important-note)Important Note

**Do NOT include `ActionType.INTERVIEW` in the `available_actions` list** when creating your agent graph. The interview action is designed to be used only manually by researchers/developers, not automatically selected by LLM agents. Including it in `available_actions` would allow agents to interview each other automatically, which is typically not desired behavior.

## [​](#complete-example)Complete Example

Copy
```
# =========== Copyright 2023 @ CAMEL-AI.org. All Rights Reserved. ===========
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# =========== Copyright 2023 @ CAMEL-AI.org. All Rights Reserved. ===========
import asyncio
import os
import sqlite3
import json

from camel.models import ModelFactory
from camel.types import ModelPlatformType, ModelType

import oasis
from oasis import (ActionType, LLMAction, ManualAction,
                   generate_twitter_agent_graph)


async def main():
    openai_model = ModelFactory.create(
        model_platform=ModelPlatformType.OPENAI,
        model_type=ModelType.GPT_4O_MINI,
    )

    # Define the available actions for the agents
    # Note: INTERVIEW is NOT included here to prevent LLM from automatically selecting it
    # INTERVIEW can still be used manually via ManualAction
    available_actions = [
        ActionType.CREATE_POST,
        ActionType.LIKE_POST,
        ActionType.REPOST,
        ActionType.FOLLOW,
        ActionType.DO_NOTHING,
        ActionType.QUOTE_POST,
        # ActionType.INTERVIEW,  # DO NOT include this - interviews should be manual only
    ]

    agent_graph = await generate_twitter_agent_graph(
        profile_path=("data/twitter_dataset/anonymous_topic_200_1h/"
                      "False_Business_0.csv"),
        model=openai_model,
        available_actions=available_actions,
    )

    # Define the path to the database
    db_path = "./data/twitter_simulation.db"

    # Delete the old database
    if os.path.exists(db_path):
        os.remove(db_path)

    # Make the environment
    env = oasis.make(
        agent_graph=agent_graph,
        platform=oasis.DefaultPlatformType.TWITTER,
        database_path=db_path,
    )

    # Run the environment
    await env.reset()

    # First timestep: Agent 0 creates a post
    actions_1 = {}
    actions_1[env.agent_graph.get_agent(0)] = ManualAction(
        action_type=ActionType.CREATE_POST,
        action_args={"content": "Earth is flat."})
    await env.step(actions_1)

    # Second timestep: Let some agents respond with LLM actions
    actions_2 = {
        agent: LLMAction()
        # Activate 5 agents with id 1, 3, 5, 7, 9
        for _, agent in env.agent_graph.get_agents([1, 3, 5, 7, 9])
    }
    await env.step(actions_2)

    # Third timestep: Agent 1 creates a post, and we interview Agent 0
    actions_3 = {}
    actions_3[env.agent_graph.get_agent(1)] = ManualAction(
        action_type=ActionType.CREATE_POST,
        action_args={"content": "Earth is not flat."})

    # Create an interview action to ask Agent 0 about their views
    actions_3[env.agent_graph.get_agent(0)] = ManualAction(
        action_type=ActionType.INTERVIEW,
        action_args={"prompt": "What do you think about the shape of the Earth? Please explain your reasoning."})

    await env.step(actions_3)

    # Fourth timestep: Let some other agents respond
    actions_4 = {
        agent: LLMAction()
        for _, agent in env.agent_graph.get_agents([2, 4, 6, 8, 10])
    }
    await env.step(actions_4)

    # Fifth timestep: Interview multiple agents
    actions_5 = {}
    actions_5[env.agent_graph.get_agent(1)] = ManualAction(
        action_type=ActionType.INTERVIEW,
        action_args={"prompt": "Why do you believe the Earth is not flat?"})

    actions_5[env.agent_graph.get_agent(2)] = ManualAction(
        action_type=ActionType.INTERVIEW,
        action_args={"prompt": "What are your thoughts on the debate about Earth's shape?"})

    await env.step(actions_5)

    # Sixth timestep: Final LLM actions for remaining agents
    actions_6 = {
        agent: LLMAction()
        for _, agent in env.agent_graph.get_agents([3, 5, 7, 9])
    }
    await env.step(actions_6)

    # Close the environment
    await env.close()

    # visualize the interview results
    print("\n=== Interview Results ===")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    # Here we query all interview records from the database
    # We use ActionType.INTERVIEW.value as the query condition to get all interview records
    # Each record contains user ID, interview information (in JSON format), and creation timestamp
    cursor.execute("""
        SELECT user_id, info, created_at
        FROM trace
        WHERE action = ?
    """, (ActionType.INTERVIEW.value,))

    # This query retrieves all interview records from the trace table
    # - user_id: the ID of the agent who was interviewed
    # - info: JSON string containing interview details (prompt, response, etc.)
    # - created_at: timestamp when the interview was conducted
    # We'll parse this data below to display the interview results
    for user_id, info_json, timestamp in cursor.fetchall():
        info = json.loads(info_json)
        print(f"\nAgent {user_id} (Timestep {timestamp}):")
        print(f"Prompt: {info.get('prompt', 'N/A')}")
        print(f"Interview ID: {info.get('interview_id', 'N/A')}")
        print(f"Response: {info.get('response', 'N/A')}")

    conn.close()


if __name__ == "__main__":
    asyncio.run(main())

```
## [​](#how-it-works)How It Works

### [​](#1-setup-and-configuration)1. Setup and Configuration

**Important**: Do NOT include `ActionType.INTERVIEW` in your available actions list. Interviews should only be conducted manually:

Copy
```
# Correct configuration - INTERVIEW is NOT included
available_actions = [
    ActionType.CREATE_POST,
    ActionType.LIKE_POST,
    ActionType.REPOST,
    ActionType.FOLLOW,
    ActionType.DO_NOTHING,
    ActionType.QUOTE_POST,
    # ActionType.INTERVIEW,  # DO NOT include - interviews are manual only
]

```

This prevents LLM agents from automatically selecting the interview action during their decision-making process. Interviews can still be conducted using `ManualAction`.

### [​](#2-conducting-interviews)2. Conducting Interviews

Use `ManualAction` with `ActionType.INTERVIEW` to conduct interviews:

Copy
```
# Single interview
interview_action = ManualAction(
    action_type=ActionType.INTERVIEW,
    action_args={"prompt": "What are your thoughts on climate change?"})

actions = {env.agent_graph.get_agent(0): interview_action}
await env.step(actions)

```
### [​](#3-multiple-interviews-in-one-step)3. Multiple Interviews in One Step

You can interview multiple agents simultaneously:

Copy
```
actions = {}
actions[env.agent_graph.get_agent(1)] = ManualAction(
    action_type=ActionType.INTERVIEW,
    action_args={"prompt": "Why do you believe the Earth is not flat?"})

actions[env.agent_graph.get_agent(2)] = ManualAction(
    action_type=ActionType.INTERVIEW,
    action_args={"prompt": "What are your thoughts on the debate about Earth's shape?"})

await env.step(actions)

```
### [​](#4-mixing-interviews-with-other-actions)4. Mixing Interviews with Other Actions

Interviews can be conducted alongside regular social media actions:

Copy
```
actions = {}
# Regular post creation
actions[env.agent_graph.get_agent(1)] = ManualAction(
    action_type=ActionType.CREATE_POST,
    action_args={"content": "Earth is not flat."})

# Interview action
actions[env.agent_graph.get_agent(0)] = ManualAction(
    action_type=ActionType.INTERVIEW,
    action_args={"prompt": "What do you think about the shape of the Earth?"})

await env.step(actions)

```
## [​](#data-storage-and-retrieval)Data Storage and Retrieval

### [​](#database-schema)Database Schema

Interview data is stored in the `trace` table with the following structure:

* `user_id`: The ID of the interviewed agent
* `action`: Set to `ActionType.INTERVIEW.value`
* `info`: JSON string containing interview details
* `created_at`: Timestamp of the interview

### [​](#retrieving-interview-results)Retrieving Interview Results

Copy
```
import sqlite3
import json

conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# Query all interview records
cursor.execute("""
    SELECT user_id, info, created_at
    FROM trace
    WHERE action = ?
""", (ActionType.INTERVIEW.value,))

for user_id, info_json, timestamp in cursor.fetchall():
    info = json.loads(info_json)
    print(f"Agent {user_id}: {info.get('response', 'N/A')}")

conn.close()

```
### [​](#interview-data-structure)Interview Data Structure

Each interview record contains:

* `prompt`: The question asked to the agent
* `interview_id`: Unique identifier for the interview
* `response`: The agent’s response to the question

## [​](#best-practices)Best Practices

### [​](#1-strategic-interview-timing)1. Strategic Interview Timing

Conduct interviews at strategic points in your simulation:

* After controversial posts to gauge reactions
* Before and after significant events
* At regular intervals to track opinion changes

### [​](#2-question-design)2. Question Design

Design effective interview questions:

* Be specific and clear
* Avoid leading questions
* Ask open-ended questions for richer responses

Copy
```
# Good examples
"What are your thoughts on renewable energy?"
"How do you feel about the recent policy changes?"
"Can you explain your reasoning behind your last post?"

# Avoid
"Don't you think renewable energy is great?" # Leading
"Yes or no: Do you like cats?" # Too restrictive

```
[Custom Prompt Simulation](/cookbooks/custom_prompt_simulation)[Visualization](/visualization/visualization)On this page

* [Interview](#interview)
* [Overview](#overview)
* [Key Features](#key-features)
* [Important Note](#important-note)
* [Complete Example](#complete-example)
* [How It Works](#how-it-works)
* [1. Setup and Configuration](#1-setup-and-configuration)
* [2. Conducting Interviews](#2-conducting-interviews)
* [3. Multiple Interviews in One Step](#3-multiple-interviews-in-one-step)
* [4. Mixing Interviews with Other Actions](#4-mixing-interviews-with-other-actions)
* [Data Storage and Retrieval](#data-storage-and-retrieval)
* [Database Schema](#database-schema)
* [Retrieving Interview Results](#retrieving-interview-results)
* [Interview Data Structure](#interview-data-structure)
* [Best Practices](#best-practices)
* [1. Strategic Interview Timing](#1-strategic-interview-timing)
* [2. Question Design](#2-question-design)
AssistantResponses are generated using AI and may contain mistakes.